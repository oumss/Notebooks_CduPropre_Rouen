{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31f1844c-232a-4928-9dae-c69679e7aa51",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installation des dépendances\n",
    "\n",
    "Pour pouvoir exécuter ce Notebook, l'environnement de développement doit être bien configuré. Puisque dans ce POC nous utilisons YoloV5, il faut installer de nombreuses dépendances dont PyTorch.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    Afin d'exécuter ce Notebook sur AWS SageMaker, il faut utiliser le kernel <code>conda_python3</code>.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    Il faut compter environ 5 minutes pour l'installation des dépendances.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e050391e-b398-4ed3-842d-6edc4c1a72af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/rkuo2000/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb5cf22-db90-49da-aaef-ba62d89cd04f",
   "metadata": {},
   "source": [
    "On installe ensuite les dépendances pour YoloV5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed2f0c1-f958-4de7-9b6c-d2356041f848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -r yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a1c99b-3666-4d5e-827f-b9d73885dd5e",
   "metadata": {},
   "source": [
    "Enfin, nous installons les dépendances liées aux frameworks Deep Learning (ici PyTorch).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Attention, il faut utiliser la bonne version de PyTorch : sur SageMaker, c'est la version <code>1.11.0+cu113</code> mais sur un autre environment, cela peut être différent (notamment sur ton PC ou sur GOogle Colab) !\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe1b86-795c-42dd-a5e8-bb3be33f9617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q \\\n",
    "    torch==1.11.0+cu113 \\\n",
    "    torchvision==0.12.0+cu113 \\\n",
    "    torchaudio==0.11.0 \\\n",
    "    gcc7 \\\n",
    "    opendatasets \\\n",
    "    pycocotools \\\n",
    "    split-folders \\\n",
    "    --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2233a9-fad3-489b-8744-60d0fb0ee7f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ceci est une petite correction nécessaire pour YoloV5\n",
    "!pip install -q --upgrade scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c85524-0e4e-41e3-8c2f-d012711993e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyse exploratoire des données\n",
    "\n",
    "Dans cette partie, nous allons étudier le jeu de données. Commençons par récupérer les données en les téléchargeant directement depuis Kaggle.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    Il est nécessaire de créer un compte sur <a href=\"https://kaggle.com\" target=\"_blank\">Kaggle</a> pour télécharger les données.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1435366b-394e-4d13-8510-92e29d5c7da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/kneroma/tacotrashdataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6995d08a-82fd-4c2d-8687-8da88c449335",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous allons **comptabiliser le nombre d'images, de catégories de déchets et d'annotations** présentes dans le jeu de données.\n",
    "\n",
    "### ➡️ À toi de jouer\n",
    "\n",
    "En parcourant le jeu de données, tu dois calculer :\n",
    "\n",
    "- le nombre de catégories dans la variable `nr_cats` ;\n",
    "- le nombre d'annotations dans la variable `nr_annotations` ;\n",
    "- le nombre d'images dans la variable `nr_images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2b687-4318-4dd1-8db0-ad8a0bcfd358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Style graphique de Seaborn\n",
    "sns.set()\n",
    "\n",
    "# Normalement, les données doivent se trouver dans le même dossier que le Notebook\n",
    "dataset_path = \"./tacotrashdataset/data\"\n",
    "anns_file_path = os.path.join(dataset_path, \"annotations.json\")\n",
    "\n",
    "# On récupère toutes les annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "# On calcule le nombre d'images, d'annotations, de catégories de déchets\n",
    "# TODO\n",
    "# ...\n",
    "\n",
    "print(\"Nombre de catégories :\", nr_cats)\n",
    "print(\"Nombre d'annotations :\", nr_annotations)\n",
    "print(\"Nombre d'images :\", nr_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cae7a5-3d04-4ffc-8680-236a14f5463a",
   "metadata": {},
   "source": [
    "### ➡️ À toi de jouer\n",
    "\n",
    "En itérant sur chaque catégorie, tu dois calculer le nombre de super catégories dans la variable `nr_super_cats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa26f3c-a0b7-43e5-8c10-207fe494cf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# On calcule le nombre de super catégories dans le dataset et on extrait les categories dans une liste\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "\n",
    "for cat_it in categories:\n",
    "    # TODO\n",
    "    # ...\n",
    "\n",
    "print(\"Nombre de super catégories :\", nr_super_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ec963-93d6-4ebe-930c-b0b090be813f",
   "metadata": {},
   "source": [
    "Maintenant, essayons de déterminer le nombre d'annotations pour chaque super catégorie.\n",
    "\n",
    "### ➡️ À toi de jouer\n",
    "\n",
    "Tracer sur un graphique (avec Matplotlib ou Seaborn) le nombre d'annotations pour chaque **super catégorie**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0911f6-340e-470f-8f08-5ba572996550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On détermine les annotations pour chaque super catégorie\n",
    "cat_ids_2_supercat_ids = {}\n",
    "for cat in categories:\n",
    "    cat_ids_2_supercat_ids[cat['id']] = super_cat_ids[cat['supercategory']]\n",
    "\n",
    "# On compte les annotations\n",
    "# TODO\n",
    "# ...\n",
    "    \n",
    "# Initialiser la figure matplotlib\n",
    "f, ax = plt.subplots(figsize=(5,10))\n",
    "\n",
    "# Conversion à un DataFrame et tri\n",
    "d = {\"Super catégories\": super_cat_names, \"Nombre d'annotations\": super_cat_histogram}\n",
    "df = pd.DataFrame(d)\n",
    "df = df.sort_values(\"Nombre d'annotations\", 0, False)\n",
    "\n",
    "# Affichage\n",
    "# TODO\n",
    "# ...\n",
    "plt.title(\"Nombre d'annotations pour chaque catégorie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc451be8-62a4-4872-a6d9-16bc2d6729f9",
   "metadata": {},
   "source": [
    "### ➡️ À toi de jouer\n",
    "\n",
    "Tracer sur un graphique (avec Matplotlib ou Seaborn) le nombre d'annotations pour chaque **catégorie**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac46ca70-764e-43e3-a15a-b431fe760291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Même traitement mais pour les catégories\n",
    "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "\n",
    "# TODO\n",
    "# ...\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5, 15))\n",
    "df = pd.DataFrame({\"Catégories\": cat_names, \"Nombre d'annotations\": cat_histogram})\n",
    "df = df.sort_values(\"Nombre d'annotations\", 0, False)\n",
    "\n",
    "# TODO\n",
    "# ...\n",
    "plt.title(\"Nombre de super catégories pour chaque catégorie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022c85bc-2984-4ee3-8978-83ea9ff629f4",
   "metadata": {},
   "source": [
    "Ce que nous montre le graphique, c'est que pour certaines annotations, **il n'y a que très peu d'exemples** : cela peut alors perturber le modèle qui peut avoir du mal à effectuer la classification. Il faudra potentiellement évaluer le modèle que sur les annotations les plus représentées.\n",
    "\n",
    "Maintenant, il est **important de bien visualiser les annotations sur les images** : cela nous permettra par exemple de savoir quelle métrique nous allons utiliser pour vérifier la qualité du modèle que nous allons construire.\n",
    "\n",
    "Pour cela, nous allons prendre des images aléatoirement selon le type de déchets qu'elles contiennent et afficher leurs bounding boxes. Pour cela, nous allons prendre comme exemple la catégorie `Clear plastic bottle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b279a-7cb6-4dd4-a510-397732850506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import random\n",
    "import pylab\n",
    "\n",
    "from PIL import Image, ExifTags\n",
    "from pycocotools.coco import COCO\n",
    "from matplotlib.patches import Polygon, Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (14,14)\n",
    "\n",
    "# Le nombre d'images à afficher\n",
    "nr_img_2_display = 1\n",
    "\n",
    "# La catégorie à afficher\n",
    "category_name = 'Clear plastic bottle'\n",
    "\n",
    "# On cherche l'orientation d'une image (car elle peut être à l'envers dans certains cas)\n",
    "for orientation in ExifTags.TAGS.keys():\n",
    "    if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "        break\n",
    "        \n",
    "# On charge les données (annotations) en tant qu'objet COCO \n",
    "coco = COCO(anns_file_path)\n",
    "\n",
    "# On récupère l'identifiant la catégorie de déchets choisie\n",
    "imgIds = []\n",
    "catIds = coco.getCatIds(catNms=[category_name])\n",
    "\n",
    "if catIds:\n",
    "    # On cherche les images contenant la catégorie de déchets choisie\n",
    "    imgIds = coco.getImgIds(catIds=catIds)\n",
    "else:\n",
    "    # On cherche les images contenant la super catégorie de déchets choisie si on ne retrouve rien avec les catégories\n",
    "    catIds = coco.getCatIds(supNms=[category_name])\n",
    "    for catId in catIds:\n",
    "        imgIds += (coco.getImgIds(catIds=catId))\n",
    "    imgIds = list(set(imgIds))\n",
    "\n",
    "# On affiche combien d'images ont été trouvées\n",
    "nr_images_found = len(imgIds) \n",
    "print(\"Nombre d'images trouvées :\", nr_images_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d4232-3e18-4e7c-8376-638077ce3222",
   "metadata": {},
   "source": [
    "### ➡️ À toi de jouer\n",
    "\n",
    "Pour chaque image tirée aléatoirement (stockées dans la variable `imgs`), afficher l'image ainsi que la segmentation et la bounding box de chaque annotation de type `Clear plastic bottle` sur l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0952df-7258-46a2-9897-dadf047931cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sélectionne N images aléatoires\n",
    "random.shuffle(imgIds)\n",
    "imgs = coco.loadImgs(imgIds[0:min(nr_img_2_display,nr_images_found)])\n",
    "\n",
    "for img in imgs:\n",
    "    image_path = dataset_path + '/' + img['file_name']\n",
    "    # On charge l'image\n",
    "    I = Image.open(image_path)\n",
    "    if I._getexif():\n",
    "        exif = dict(I._getexif().items())\n",
    "        # Rotation de l'image si nécessaire\n",
    "        if orientation in exif:\n",
    "            if exif[orientation] == 3:\n",
    "                I = I.rotate(180,expand=True)\n",
    "            if exif[orientation] == 6:\n",
    "                I = I.rotate(270,expand=True)\n",
    "            if exif[orientation] == 8:\n",
    "                I = I.rotate(90,expand=True)\n",
    "    \n",
    "    # Affichage de l'image\n",
    "    fig,ax = plt.subplots(1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(I)\n",
    "\n",
    "    # Chargement des annotations \n",
    "    annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
    "    anns_sel = coco.loadAnns(annIds)\n",
    "    \n",
    "    # Affichage des segmentations et des bounding boxes à partir des annotations\n",
    "    for ann in anns_sel:\n",
    "        # TODO\n",
    "        # ...\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095de456-5661-4192-b047-e9d49431a667",
   "metadata": {},
   "source": [
    "On voit à la fois la segmentation (en trait plein) et la bounding box (en pointillées)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
